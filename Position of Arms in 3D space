import cv2
import mediapipe as mp
import math
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D as plt3D

import cv2
import mediapipe as mp
import math

cap = cv2.VideoCapture(0)

# Initialize Mediapipe Pose model
mpPose = mp.solutions.pose

# Initialize Pose model
pose = mpPose.Pose()

# Initialize Mediapipe hand model
mpHands = mp.solutions.hands

# Initialize hand model
hands = mpHands.Hands()

# Initialize Mediapipe drawing
mpDraw = mp.solutions.drawing_utils

w = 0
h = 0
c = 0

armPositionFigure = plt.figure()
armAxis = armPositionFigure.add_subplot(111, projection = '3d')
armAxis.view_init(elev=120, azim = 30)

#plt.rcParams["figure.figsize"] = [7.50, 3.50]
#plt.rcParams["figure.autolayout"] = True

while True:
    exist, frame = cap.read()
    frame = cv2.flip(frame,1)

    # Check if the frame was successfully captured
    if not (exist):
        break

    # This is needed because Mediapipe needs image to be in RGB color format
    rgbFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # Finds all pose features in frame
    resultsPose = pose.process(rgbFrame)


    # Gets height and width of frame
    h, w, c = frame.shape


    # Initalizations so calculations can be done outside of conditional statements to speed up processing time

    leftShoulder_x = 0
    leftShoulder_y = 0

    leftElbow_x = 0
    leftElbow_y = 0

    leftWrist_x = 0
    leftWrist_y = 0



    rightShoulder_x = 0
    rightShoulder_y = 0

    rightElbow_x = 0
    rightElbow_y = 0

    rightWrist_x = 0
    rightWrist_y = 0


    # Checks to see if pose landmarks are detected
    if resultsPose.pose_landmarks:

                                                    # Features on Left Side

        # For Left Shoulder
        leftShoulder = resultsPose.pose_landmarks.landmark[12]

        # Convert landmarks to pixel coordinates and draw landmarks
        leftShoulder_x = int(leftShoulder.x * w)
        leftShoulder_y = int(leftShoulder.y * h)
        cv2.circle(frame, (leftShoulder_x, leftShoulder_y), 5, (0, 0, 255), -1)

        



        # For Left Elbow
        leftElbow = resultsPose.pose_landmarks.landmark[14]

        # Convert landmarks to pixel coordinates and draw landmarks
        leftElbow_x = int(leftElbow.x * w)
        leftElbow_y = int(leftElbow.y * h)
        cv2.circle(frame, (leftElbow_x, leftElbow_y), 5, (0, 0, 255), -1)




        # For Left Wrist
        leftWrist = resultsPose.pose_landmarks.landmark[16]

        # Convert landmarks to pixel coordinates and draw landmarks
        leftWrist_x = int(leftWrist.x * w)
        leftWrist_y = int(leftWrist.y * h)
        cv2.circle(frame, (leftWrist_x, leftWrist_y), 5, (0, 0, 255), -1)



                                                    # Features on Right Side


        # For Right Shoulder
        rightShoulder = resultsPose.pose_landmarks.landmark[11]

        # Convert landmarks to pixel coordinates and draw landmarks
        rightShoulder_x = int(rightShoulder.x * w)
        rightShoulder_y = int(rightShoulder.y * h)
        cv2.circle(frame, (rightShoulder_x, rightShoulder_y), 5, (0, 0, 255), -1)



        # For Right Elbow
        rightElbow = resultsPose.pose_landmarks.landmark[13]

        # Convert landmarks to pixel coordinates and draw landmarks
        rightElbow_x = int(rightElbow.x * w)
        rightElbow_y = int(rightElbow.y * h)
        cv2.circle(frame, (rightElbow_x, rightElbow_y), 5, (0, 0, 255), -1)



        # For Right Wrist
        rightWrist = resultsPose.pose_landmarks.landmark[15]

        # Convert landmarks to pixel coordinates and draw landmarks
        rightWrist_x = int(rightWrist.x * w)
        rightWrist_y = int(rightWrist.y * h)
        cv2.circle(frame, (rightWrist_x, rightWrist_y), 5, (0, 0, 255), -1)



                                    # Connecting each feature point to make a better model of each arm
        
        # Connecting Left Shoulder to Left Elbow
        cv2.line(frame, (leftShoulder_x, leftShoulder_y), (leftElbow_x, leftElbow_y), (255, 255, 255), 2)

        # Connecting Left Elbow to Left Wrist
        cv2.line(frame, (leftElbow_x, leftElbow_y), (leftWrist_x, leftWrist_y), (255, 255, 255), 2)



        # Connecting Right Shoulder to Right Elbow
        cv2.line(frame, (rightShoulder_x, rightShoulder_y), (rightElbow_x, rightElbow_y), (255, 255, 255), 2)        

        # Connecting Right Elbow to Right Wrist
        cv2.line(frame, (rightElbow_x, rightElbow_y), (rightWrist_x, rightWrist_y), (255, 255, 255), 2)

        # Plots the 3D Points of Right Arm
        armAxis.scatter(rightElbow_x,rightElbow_y,0,c='r', marker='o')
        armAxis.scatter(rightShoulder_x,rightShoulder_y,0,c='r', marker='o')
        armAxis.scatter(rightWrist_x,rightWrist_y,0,c='r', marker='o')


        # Plots the 3D Points of Left Arm
        armAxis.scatter(leftElbow_x,leftElbow_y,2,c='g', marker='o')
        armAxis.scatter(leftShoulder_x,leftShoulder_y,2,c='g', marker='o')
        armAxis.scatter(leftWrist_x,leftWrist_y,2,c='g', marker='o')

        
        # Drawing Lines between all of the Left Arm 3D points
        #   (x,y,z of Shoulder) to (x,y,z of Elbow) to (x,y,z of Wrist)
        armAxis.plot([leftShoulder_x, leftElbow_x, leftWrist_x], # X Coordinates
                     [leftShoulder_y, leftElbow_y, leftWrist_y], # Y Coordinates
                     [0, 0, 0], c='g')                              # Z Coordinates

        
        # Drawing Lines between all of the Right Arm 3D points
        #   (x,y,z of Shoulder) to (x,y,z of Elbow) to (x,y,z of Wrist)
        armAxis.plot([rightShoulder_x, rightElbow_x, rightWrist_x], # X Coordinates
                     [rightShoulder_y, rightElbow_y, rightWrist_y], # Y Coordinates
                     [0, 0, 0], c='r')                              # Z Coordinates

        # Bounds the x,y,z axis to the height and width of the frame
        armAxis.set_xlim([-w, w])
        armAxis.set_ylim([0, h])
        armAxis.set_zlim([-w, w])

        

    
    # Finds all hand features in frame
    resultsHands = hands.process(rgbFrame)

    # Check to see if hand landmarks are detected
    if resultsHands.multi_hand_landmarks:
        for handLandmarks in resultsHands.multi_hand_landmarks:
            mpDraw.draw_landmarks(frame, handLandmarks, mpHands.HAND_CONNECTIONS)

            # Get the coordinates of the thumb and index finger tips
            thumbTip = handLandmarks.landmark[4]
            thumbTip_x = int(thumbTip.x * w)
            thumbTip_y = int(thumbTip.y * h)

            armAxis.scatter(thumbTip_x, thumbTip_y, 0)




            indexTip = handLandmarks.landmark[8]
            indexTip_x = int(indexTip.x * w)
            indexTip_y = int(indexTip.y * h)

            armAxis.scatter(indexTip_x, indexTip_y, 0)




            middleTip = handLandmarks.landmark[12]
            middleTip_x = int(middleTip.x * w)
            middleTip_y = int(middleTip.y * h)

            armAxis.scatter(middleTip_x, middleTip_y, 0)




            indexNuckle = handLandmarks.landmark[5]
            indexNuckle_x = int(indexNuckle.x * w)
            indexNuckle_y = int(indexNuckle.y * h)




            armAxis.plot([thumbTip_x, indexTip_x, indexNuckle_x, middleTip_x],
                         [thumbTip_y, indexTip_y, indexNuckle_y, middleTip_y],
                         [0, 0, 0, 0], c='b')


            # Calculate the pixel distance between the thumb and index finger tips
            distance = math.dist((thumbTip_x, thumbTip_y), (indexTip_x, indexTip_y))

            # Set a threshold for finger touch
            touchThreshold = 0.064  # Experiment with the value

            # Calculate the size of the hand (use the distance between two specified landmarks)
            hand_size = math.sqrt(math.pow((handLandmarks.landmark[0].x - handLandmarks.landmark[5].x), 2) + math.pow((handLandmarks.landmark[0].y - handLandmarks.landmark[5].y), 2))

            # Calculate the relative distance (distance normalized by hand size)
            relativeDistance = distance / hand_size

            # Check if the thumb and index finger tips are touching
            if relativeDistance < touchThreshold:
                cv2.putText(frame, "Fingers Touching", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
        
        # It can't differentiate between both hands so the line is switching between the two wrists. Look into later.

        #handWrist = resultsHands.multi_hand_landmarks[0].landmark[mpHands.HandLandmark.WRIST]
        #handWrist_x, handWrist_y = int(handWrist.x * w), int(handWrist.y * h)

        #cv2.line(frame, (rightWrist_x, rightWrist_y), (handWrist_x, handWrist_y), (255, 255, 255), 2)


    # Next, the angle needs to be computed between the forearm and the bisep to send to a robot?
        # Law of cosines to find angle inbetween forearm
    # I think angle should be the same no matter the distance from the camera as a result of it relating the two of them together.
    
    # Are we connecting to a robot or just doing a 3D render. If so how do we accomplish either of these?

    plt.pause(0.01) # Plots then waits 0.01 seconds

    armAxis.cla() # Clears all axis

    cv2.imshow('Arms', frame)

    # Break the loop when 'Esc' key is pressed
    if cv2.waitKey(1) == 27:
        break

cap.release()
cv2.destroyAllWindows()
